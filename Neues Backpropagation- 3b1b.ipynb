{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914a06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation_3b2b(z2, a2, z3, a3, w3, z4, a4, w4, labels, daten):\n",
    "    \"\"\"\n",
    "    Backpropagation basierend auf den expliziten Formeln von 3Blue1Brown.\n",
    "    Nutzt die Kettenregel: dC/dw = dC/da * da/dz * dz/dw\n",
    "    \"\"\"\n",
    "    # Anzahl der Trainingsbeispiele (n) für die Durchschnittsbildung\n",
    "    n = labels.size\n",
    "    \n",
    "    # Der gewünschte Ziel-Vektor (y)\n",
    "    y = eins_aus_n(labels)\n",
    "\n",
    "    # --- SCHICHT 3 (Ausgabeschicht) ---\n",
    "    # 1. Ableitung der Kostenfunktion nach der Aktivierung: 2 * (aL - y) \n",
    "    dC_da4 = 2 * (a4 - y)\n",
    "    \n",
    "    # 2. Ableitung der Aktivierung nach der gewichteten Summe: sigma'(zL)\n",
    "    da4_dz4 = ableitung_sigmoid(z4)\n",
    "    \n",
    "    # Zusammengefasst (Fehler der Schicht 3): dC/dz4\n",
    "    dz4 = dC_da4 * da4_dz4 \n",
    "\n",
    "    # Gradienten für Gewichte und Biases der Schicht 3 \n",
    "    # dw4 = dz4 * a3 (Durchschnitt über alle Beispiele n)\n",
    "    dw4 = (1/n) * dz4.dot(a3.T)\n",
    "    db4 = (1/n) * np.sum(dz4, axis=1, keepdims=True)\n",
    "\n",
    "    # --- SCHICHT 2 (Versteckte Schicht) ---\n",
    "    # 1. Einfluss der Aktivierung a3 auf die Kosten (über alle Pfade j summiert)\n",
    "    # dC/da3 = w4.T * dz4\n",
    "    dC_da3 = w4.T.dot(dz4)\n",
    "    \n",
    "    # 2. Fehler der Schicht 2: dC/da3 * sigma'(z3)\n",
    "    dz3 = dC_da3 * ableitung_sigmoid(z3)\n",
    "\n",
    "    dw3 = (1/n) * dz3.dot(a2.T)\n",
    "    db3 = (1/n) * np.sum(dz3, axis=1, keepdims=True)\n",
    "\n",
    "    # --- SCHICHT 1 (Erste versteckte Schicht) ---\n",
    "    # Analog zur Schicht 2 [11, 12]\n",
    "    dC_da2 = w3.T.dot(dz3)\n",
    "    dz2 = dC_da2 * ableitung_sigmoid(z2)\n",
    "\n",
    "    dw2 = (1/n) * dz2.dot(daten.T)\n",
    "    db2 = (1/n) * np.sum(dz2, axis=1, keepdims=True)\n",
    "\n",
    "    return dw2, db2, dw3, db3, dw4, db4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9097276b",
   "metadata": {},
   "source": [
    "Die grünen und orangen Kommentare sind von Google NotebookLM.   \n",
    "  \n",
    "Die Ableitungen werden Schritt für Schritt wie in der ABA ausgeführt. Außerdem wird hier nicht das Matrizenprodukt verwendet, sondern die Matrizen werden elementweise multipliziert.  \n",
    "  \n",
    "Der erste entscheidende Unterschied ist die Ableitung nach a4, anschließend wird dies mit der Ableitung der Aktivierungsfunktion der gewichteten Summe multipliziert.    \n",
    "  \n",
    "Um nun die Änderungen der Gewichte auszurechnen, wird dies gemäß der Formel aus der ABA mit den Aktivierungen der vorherigen Schicht multipliziert (diesmal Matrizenmultiplikation) und durch die Anzahl der Trainingsbeispiele dividiert, da diese zuvor in der Matrizenmultiplikation aufsummiert wurden.  \n",
    "    \n",
    "Um nun nach a3 abzuleiten, werden wie im anderen Code die Gewichtsmatrizen transponiert und mit der gewichtenten Summe der letzten Schicht Matrix-multipliziert. Dies wird für alle Schichten gemacht, bis die Änderungen für alle Gewichts- und Biasmatrizen bekannt sind. Diese werden dann wie im anderen Code geändert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e374fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientenabstieg(daten,label,wiederholungen,lernrate):\n",
    "    w1,b1,w2,b2,w3,b3=matrizen_erstellen()\n",
    "    for i in range(wiederholungen):\n",
    "        z1,a1,z2,a2,z3,a3=Abfrage(w1,b1,w2,b2,w3,b3, daten)\n",
    "        dw1,db1,dw2,db2,dw3,db3=backpropagation(z1,a1,z2,a2,w2,z3,a3,w3,label,daten, )\n",
    "        w1,b1,w2,b2,w3,b3=parameter_aktualisieren(w1,b1,w2,b2,w3,b3,dw1,db1,dw2,db2,dw3,db3,lernrate)\n",
    "        if i%100==0:\n",
    "            print(\"Wiederholungen: \",i)\n",
    "            print(\"Accuracy: \", wie_akkurat(vorhersage_machen(a3),label))\n",
    "    return w1,b1,w2,b2,w3,b3,l"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
